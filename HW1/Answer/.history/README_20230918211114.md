## Q1: Regex

- checking if the input contains a doctors name

## Q2: NLTK

- running word_tokenize and sent_tokenize methods of nltk library on a sample text

## Q3: Normalization

- removing extra characters in the input word

## Q4: Tokenization

- running these tokenizers on 4 different text samples:
  - TreebankWordTokenizer
  - RegexpTokenizer
  - WhitespaceTokenizer
  - WordPunctTokenizer

## Q5: Stemming

- running these stemmers on a sample text:
  - LancasterStemmer
  - PorterStemmer

## Q6: Preprocessing

- preprocessing a datasets containing around 60K tweets, by going through these steps:
-
